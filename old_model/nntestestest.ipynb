{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Ciner\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\tqdm\\auto.py:22: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/300\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Ciner\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\tensorflow\\python\\util\\dispatch.py:1082: UserWarning: \"`sparse_categorical_crossentropy` received `from_logits=True`, but the `output` argument was produced by a sigmoid or softmax activation and thus does not represent logits. Was this intended?\"\n",
      "  return dispatch_target(*args, **kwargs)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "10/10 - 1s - loss: 1.3865 - accuracy: 0.2114 - 1s/epoch - 146ms/step\n",
      "Epoch 2/300\n",
      "10/10 - 0s - loss: 1.3855 - accuracy: 0.2871 - 9ms/epoch - 900us/step\n",
      "Epoch 3/300\n",
      "10/10 - 0s - loss: 1.3848 - accuracy: 0.3060 - 9ms/epoch - 900us/step\n",
      "Epoch 4/300\n",
      "10/10 - 0s - loss: 1.3839 - accuracy: 0.3281 - 9ms/epoch - 900us/step\n",
      "Epoch 5/300\n",
      "10/10 - 0s - loss: 1.3827 - accuracy: 0.3628 - 8ms/epoch - 800us/step\n",
      "Epoch 6/300\n",
      "10/10 - 0s - loss: 1.3817 - accuracy: 0.3596 - 9ms/epoch - 900us/step\n",
      "Epoch 7/300\n",
      "10/10 - 0s - loss: 1.3807 - accuracy: 0.3849 - 9ms/epoch - 900us/step\n",
      "Epoch 8/300\n",
      "10/10 - 0s - loss: 1.3789 - accuracy: 0.4101 - 10ms/epoch - 1ms/step\n",
      "Epoch 9/300\n",
      "10/10 - 0s - loss: 1.3771 - accuracy: 0.4353 - 10ms/epoch - 1ms/step\n",
      "Epoch 10/300\n",
      "10/10 - 0s - loss: 1.3755 - accuracy: 0.4953 - 9ms/epoch - 900us/step\n",
      "Epoch 11/300\n",
      "10/10 - 0s - loss: 1.3734 - accuracy: 0.4700 - 10ms/epoch - 1ms/step\n",
      "Epoch 12/300\n",
      "10/10 - 0s - loss: 1.3711 - accuracy: 0.5110 - 10ms/epoch - 1ms/step\n",
      "Epoch 13/300\n",
      "10/10 - 0s - loss: 1.3687 - accuracy: 0.5552 - 11ms/epoch - 1ms/step\n",
      "Epoch 14/300\n",
      "10/10 - 0s - loss: 1.3656 - accuracy: 0.5899 - 10ms/epoch - 1ms/step\n",
      "Epoch 15/300\n",
      "10/10 - 0s - loss: 1.3629 - accuracy: 0.5804 - 9ms/epoch - 900us/step\n",
      "Epoch 16/300\n",
      "10/10 - 0s - loss: 1.3589 - accuracy: 0.6025 - 9ms/epoch - 900us/step\n",
      "Epoch 17/300\n",
      "10/10 - 0s - loss: 1.3556 - accuracy: 0.6025 - 9ms/epoch - 900us/step\n",
      "Epoch 18/300\n",
      "10/10 - 0s - loss: 1.3503 - accuracy: 0.6057 - 9ms/epoch - 900us/step\n",
      "Epoch 19/300\n",
      "10/10 - 0s - loss: 1.3469 - accuracy: 0.5931 - 9ms/epoch - 900us/step\n",
      "Epoch 20/300\n",
      "10/10 - 0s - loss: 1.3410 - accuracy: 0.6025 - 10ms/epoch - 1ms/step\n",
      "Epoch 21/300\n",
      "10/10 - 0s - loss: 1.3357 - accuracy: 0.6057 - 10ms/epoch - 1ms/step\n",
      "Epoch 22/300\n",
      "10/10 - 0s - loss: 1.3292 - accuracy: 0.5899 - 9ms/epoch - 900us/step\n",
      "Epoch 23/300\n",
      "10/10 - 0s - loss: 1.3227 - accuracy: 0.6088 - 9ms/epoch - 900us/step\n",
      "Epoch 24/300\n",
      "10/10 - 0s - loss: 1.3162 - accuracy: 0.6215 - 10ms/epoch - 1ms/step\n",
      "Epoch 25/300\n",
      "10/10 - 0s - loss: 1.3080 - accuracy: 0.6404 - 9ms/epoch - 900us/step\n",
      "Epoch 26/300\n",
      "10/10 - 0s - loss: 1.2982 - accuracy: 0.6341 - 9ms/epoch - 900us/step\n",
      "Epoch 27/300\n",
      "10/10 - 0s - loss: 1.2924 - accuracy: 0.6278 - 9ms/epoch - 900us/step\n",
      "Epoch 28/300\n",
      "10/10 - 0s - loss: 1.2833 - accuracy: 0.6372 - 9ms/epoch - 900us/step\n",
      "Epoch 29/300\n",
      "10/10 - 0s - loss: 1.2737 - accuracy: 0.6372 - 14ms/epoch - 1ms/step\n",
      "Epoch 30/300\n",
      "10/10 - 0s - loss: 1.2626 - accuracy: 0.6467 - 11ms/epoch - 1ms/step\n",
      "Epoch 31/300\n",
      "10/10 - 0s - loss: 1.2519 - accuracy: 0.6562 - 10ms/epoch - 1ms/step\n",
      "Epoch 32/300\n",
      "10/10 - 0s - loss: 1.2412 - accuracy: 0.6688 - 12ms/epoch - 1ms/step\n",
      "Epoch 33/300\n",
      "10/10 - 0s - loss: 1.2307 - accuracy: 0.6877 - 10ms/epoch - 1ms/step\n",
      "Epoch 34/300\n",
      "10/10 - 0s - loss: 1.2167 - accuracy: 0.6751 - 9ms/epoch - 900us/step\n",
      "Epoch 35/300\n",
      "10/10 - 0s - loss: 1.2050 - accuracy: 0.6845 - 9ms/epoch - 900us/step\n",
      "Epoch 36/300\n",
      "10/10 - 0s - loss: 1.1906 - accuracy: 0.7003 - 9ms/epoch - 900us/step\n",
      "Epoch 37/300\n",
      "10/10 - 0s - loss: 1.1810 - accuracy: 0.6877 - 10ms/epoch - 1ms/step\n",
      "Epoch 38/300\n",
      "10/10 - 0s - loss: 1.1647 - accuracy: 0.6845 - 11ms/epoch - 1ms/step\n",
      "Epoch 39/300\n",
      "10/10 - 0s - loss: 1.1562 - accuracy: 0.6940 - 9ms/epoch - 900us/step\n",
      "Epoch 40/300\n",
      "10/10 - 0s - loss: 1.1443 - accuracy: 0.7035 - 9ms/epoch - 900us/step\n",
      "Epoch 41/300\n",
      "10/10 - 0s - loss: 1.1291 - accuracy: 0.7256 - 9ms/epoch - 900us/step\n",
      "Epoch 42/300\n",
      "10/10 - 0s - loss: 1.1165 - accuracy: 0.7161 - 9ms/epoch - 900us/step\n",
      "Epoch 43/300\n",
      "10/10 - 0s - loss: 1.1047 - accuracy: 0.7035 - 9ms/epoch - 900us/step\n",
      "Epoch 44/300\n",
      "10/10 - 0s - loss: 1.0905 - accuracy: 0.7319 - 9ms/epoch - 900us/step\n",
      "Epoch 45/300\n",
      "10/10 - 0s - loss: 1.0753 - accuracy: 0.7350 - 9ms/epoch - 900us/step\n",
      "Epoch 46/300\n",
      "10/10 - 0s - loss: 1.0630 - accuracy: 0.7256 - 9ms/epoch - 900us/step\n",
      "Epoch 47/300\n",
      "10/10 - 0s - loss: 1.0503 - accuracy: 0.7350 - 10ms/epoch - 1ms/step\n",
      "Epoch 48/300\n",
      "10/10 - 0s - loss: 1.0355 - accuracy: 0.7319 - 9ms/epoch - 900us/step\n",
      "Epoch 49/300\n",
      "10/10 - 0s - loss: 1.0229 - accuracy: 0.7476 - 9ms/epoch - 900us/step\n",
      "Epoch 50/300\n",
      "10/10 - 0s - loss: 1.0120 - accuracy: 0.7413 - 9ms/epoch - 900us/step\n",
      "Epoch 51/300\n",
      "10/10 - 0s - loss: 0.9977 - accuracy: 0.7382 - 10ms/epoch - 1ms/step\n",
      "Epoch 52/300\n",
      "10/10 - 0s - loss: 0.9771 - accuracy: 0.7539 - 9ms/epoch - 900us/step\n",
      "Epoch 53/300\n",
      "10/10 - 0s - loss: 0.9722 - accuracy: 0.7539 - 9ms/epoch - 900us/step\n",
      "Epoch 54/300\n",
      "10/10 - 0s - loss: 0.9540 - accuracy: 0.7571 - 9ms/epoch - 900us/step\n",
      "Epoch 55/300\n",
      "10/10 - 0s - loss: 0.9386 - accuracy: 0.7697 - 10ms/epoch - 1ms/step\n",
      "Epoch 56/300\n",
      "10/10 - 0s - loss: 0.9310 - accuracy: 0.7603 - 9ms/epoch - 900us/step\n",
      "Epoch 57/300\n",
      "10/10 - 0s - loss: 0.9136 - accuracy: 0.7760 - 9ms/epoch - 900us/step\n",
      "Epoch 58/300\n",
      "10/10 - 0s - loss: 0.9043 - accuracy: 0.7760 - 9ms/epoch - 900us/step\n",
      "Epoch 59/300\n",
      "10/10 - 0s - loss: 0.8881 - accuracy: 0.7855 - 8ms/epoch - 800us/step\n",
      "Epoch 60/300\n",
      "10/10 - 0s - loss: 0.8761 - accuracy: 0.7950 - 9ms/epoch - 900us/step\n",
      "Epoch 61/300\n",
      "10/10 - 0s - loss: 0.8698 - accuracy: 0.8013 - 9ms/epoch - 900us/step\n",
      "Epoch 62/300\n",
      "10/10 - 0s - loss: 0.8528 - accuracy: 0.8044 - 9ms/epoch - 900us/step\n",
      "Epoch 63/300\n",
      "10/10 - 0s - loss: 0.8393 - accuracy: 0.8170 - 9ms/epoch - 900us/step\n",
      "Epoch 64/300\n",
      "10/10 - 0s - loss: 0.8304 - accuracy: 0.8265 - 9ms/epoch - 900us/step\n",
      "Epoch 65/300\n",
      "10/10 - 0s - loss: 0.8131 - accuracy: 0.8139 - 10ms/epoch - 1ms/step\n",
      "Epoch 66/300\n",
      "10/10 - 0s - loss: 0.8010 - accuracy: 0.8328 - 8ms/epoch - 800us/step\n",
      "Epoch 67/300\n",
      "10/10 - 0s - loss: 0.7887 - accuracy: 0.8391 - 9ms/epoch - 900us/step\n",
      "Epoch 68/300\n",
      "10/10 - 0s - loss: 0.7800 - accuracy: 0.8486 - 9ms/epoch - 900us/step\n",
      "Epoch 69/300\n",
      "10/10 - 0s - loss: 0.7665 - accuracy: 0.8454 - 9ms/epoch - 900us/step\n",
      "Epoch 70/300\n",
      "10/10 - 0s - loss: 0.7573 - accuracy: 0.8549 - 9ms/epoch - 900us/step\n",
      "Epoch 71/300\n",
      "10/10 - 0s - loss: 0.7467 - accuracy: 0.8486 - 10ms/epoch - 1ms/step\n",
      "Epoch 72/300\n",
      "10/10 - 0s - loss: 0.7349 - accuracy: 0.8549 - 9ms/epoch - 900us/step\n",
      "Epoch 73/300\n",
      "10/10 - 0s - loss: 0.7183 - accuracy: 0.8486 - 10ms/epoch - 1ms/step\n",
      "Epoch 74/300\n",
      "10/10 - 0s - loss: 0.7120 - accuracy: 0.8580 - 8ms/epoch - 800us/step\n",
      "Epoch 75/300\n",
      "10/10 - 0s - loss: 0.7007 - accuracy: 0.8580 - 10ms/epoch - 1ms/step\n",
      "Epoch 76/300\n",
      "10/10 - 0s - loss: 0.6879 - accuracy: 0.8675 - 9ms/epoch - 900us/step\n",
      "Epoch 77/300\n",
      "10/10 - 0s - loss: 0.6757 - accuracy: 0.8707 - 8ms/epoch - 800us/step\n",
      "Epoch 78/300\n",
      "10/10 - 0s - loss: 0.6716 - accuracy: 0.8675 - 9ms/epoch - 900us/step\n",
      "Epoch 79/300\n",
      "10/10 - 0s - loss: 0.6573 - accuracy: 0.8644 - 10ms/epoch - 1ms/step\n",
      "Epoch 80/300\n",
      "10/10 - 0s - loss: 0.6494 - accuracy: 0.8738 - 8ms/epoch - 800us/step\n",
      "Epoch 81/300\n",
      "10/10 - 0s - loss: 0.6419 - accuracy: 0.8770 - 9ms/epoch - 900us/step\n",
      "Epoch 82/300\n",
      "10/10 - 0s - loss: 0.6296 - accuracy: 0.8707 - 10ms/epoch - 1ms/step\n",
      "Epoch 83/300\n",
      "10/10 - 0s - loss: 0.6215 - accuracy: 0.8801 - 8ms/epoch - 800us/step\n",
      "Epoch 84/300\n",
      "10/10 - 0s - loss: 0.6146 - accuracy: 0.8801 - 9ms/epoch - 900us/step\n",
      "Epoch 85/300\n",
      "10/10 - 0s - loss: 0.6035 - accuracy: 0.8864 - 9ms/epoch - 900us/step\n",
      "Epoch 86/300\n",
      "10/10 - 0s - loss: 0.5937 - accuracy: 0.8738 - 10ms/epoch - 1ms/step\n",
      "Epoch 87/300\n",
      "10/10 - 0s - loss: 0.5857 - accuracy: 0.8864 - 9ms/epoch - 900us/step\n",
      "Epoch 88/300\n",
      "10/10 - 0s - loss: 0.5771 - accuracy: 0.8833 - 9ms/epoch - 900us/step\n",
      "Epoch 89/300\n",
      "10/10 - 0s - loss: 0.5678 - accuracy: 0.8927 - 12ms/epoch - 1ms/step\n",
      "Epoch 90/300\n",
      "10/10 - 0s - loss: 0.5541 - accuracy: 0.8991 - 12ms/epoch - 1ms/step\n",
      "Epoch 91/300\n",
      "10/10 - 0s - loss: 0.5480 - accuracy: 0.8959 - 9ms/epoch - 900us/step\n",
      "Epoch 92/300\n",
      "10/10 - 0s - loss: 0.5450 - accuracy: 0.8864 - 9ms/epoch - 900us/step\n",
      "Epoch 93/300\n",
      "10/10 - 0s - loss: 0.5378 - accuracy: 0.8991 - 10ms/epoch - 1ms/step\n",
      "Epoch 94/300\n",
      "10/10 - 0s - loss: 0.5258 - accuracy: 0.9022 - 8ms/epoch - 800us/step\n",
      "Epoch 95/300\n",
      "10/10 - 0s - loss: 0.5234 - accuracy: 0.9022 - 9ms/epoch - 900us/step\n",
      "Epoch 96/300\n",
      "10/10 - 0s - loss: 0.5122 - accuracy: 0.9022 - 9ms/epoch - 900us/step\n",
      "Epoch 97/300\n",
      "10/10 - 0s - loss: 0.5074 - accuracy: 0.8959 - 8ms/epoch - 800us/step\n",
      "Epoch 98/300\n",
      "10/10 - 0s - loss: 0.4996 - accuracy: 0.8959 - 10ms/epoch - 1ms/step\n",
      "Epoch 99/300\n",
      "10/10 - 0s - loss: 0.4927 - accuracy: 0.9054 - 9ms/epoch - 900us/step\n",
      "Epoch 100/300\n",
      "10/10 - 0s - loss: 0.4891 - accuracy: 0.8991 - 10ms/epoch - 1ms/step\n",
      "Epoch 101/300\n",
      "10/10 - 0s - loss: 0.4792 - accuracy: 0.9022 - 8ms/epoch - 800us/step\n",
      "Epoch 102/300\n",
      "10/10 - 0s - loss: 0.4724 - accuracy: 0.9085 - 9ms/epoch - 900us/step\n",
      "Epoch 103/300\n",
      "10/10 - 0s - loss: 0.4668 - accuracy: 0.9022 - 9ms/epoch - 900us/step\n",
      "Epoch 104/300\n",
      "10/10 - 0s - loss: 0.4565 - accuracy: 0.9054 - 10ms/epoch - 1ms/step\n",
      "Epoch 105/300\n",
      "10/10 - 0s - loss: 0.4550 - accuracy: 0.9148 - 8ms/epoch - 800us/step\n",
      "Epoch 106/300\n",
      "10/10 - 0s - loss: 0.4457 - accuracy: 0.9117 - 9ms/epoch - 900us/step\n",
      "Epoch 107/300\n",
      "10/10 - 0s - loss: 0.4413 - accuracy: 0.9054 - 8ms/epoch - 800us/step\n",
      "Epoch 108/300\n",
      "10/10 - 0s - loss: 0.4383 - accuracy: 0.9148 - 8ms/epoch - 800us/step\n",
      "Epoch 109/300\n",
      "10/10 - 0s - loss: 0.4282 - accuracy: 0.9085 - 9ms/epoch - 900us/step\n",
      "Epoch 110/300\n",
      "10/10 - 0s - loss: 0.4191 - accuracy: 0.9180 - 8ms/epoch - 800us/step\n",
      "Epoch 111/300\n",
      "10/10 - 0s - loss: 0.4166 - accuracy: 0.9180 - 9ms/epoch - 900us/step\n",
      "Epoch 112/300\n",
      "10/10 - 0s - loss: 0.4138 - accuracy: 0.9243 - 10ms/epoch - 1ms/step\n",
      "Epoch 113/300\n",
      "10/10 - 0s - loss: 0.4092 - accuracy: 0.9243 - 10ms/epoch - 1ms/step\n",
      "Epoch 114/300\n",
      "10/10 - 0s - loss: 0.4047 - accuracy: 0.9180 - 9ms/epoch - 900us/step\n",
      "Epoch 115/300\n",
      "10/10 - 0s - loss: 0.4009 - accuracy: 0.9243 - 8ms/epoch - 800us/step\n",
      "Epoch 116/300\n",
      "10/10 - 0s - loss: 0.3941 - accuracy: 0.9274 - 9ms/epoch - 900us/step\n",
      "Epoch 117/300\n",
      "10/10 - 0s - loss: 0.3898 - accuracy: 0.9243 - 9ms/epoch - 900us/step\n",
      "Epoch 118/300\n",
      "10/10 - 0s - loss: 0.3891 - accuracy: 0.9243 - 9ms/epoch - 900us/step\n",
      "Epoch 119/300\n",
      "10/10 - 0s - loss: 0.3825 - accuracy: 0.9274 - 12ms/epoch - 1ms/step\n",
      "Epoch 120/300\n",
      "10/10 - 0s - loss: 0.3765 - accuracy: 0.9243 - 10ms/epoch - 1ms/step\n",
      "Epoch 121/300\n",
      "10/10 - 0s - loss: 0.3709 - accuracy: 0.9306 - 9ms/epoch - 900us/step\n",
      "Epoch 122/300\n",
      "10/10 - 0s - loss: 0.3615 - accuracy: 0.9274 - 9ms/epoch - 900us/step\n",
      "Epoch 123/300\n",
      "10/10 - 0s - loss: 0.3596 - accuracy: 0.9338 - 9ms/epoch - 900us/step\n",
      "Epoch 124/300\n",
      "10/10 - 0s - loss: 0.3577 - accuracy: 0.9338 - 8ms/epoch - 800us/step\n",
      "Epoch 125/300\n",
      "10/10 - 0s - loss: 0.3517 - accuracy: 0.9338 - 10ms/epoch - 1ms/step\n",
      "Epoch 126/300\n",
      "10/10 - 0s - loss: 0.3519 - accuracy: 0.9338 - 8ms/epoch - 800us/step\n",
      "Epoch 127/300\n",
      "10/10 - 0s - loss: 0.3452 - accuracy: 0.9369 - 13ms/epoch - 1ms/step\n",
      "Epoch 128/300\n",
      "10/10 - 0s - loss: 0.3443 - accuracy: 0.9338 - 9ms/epoch - 900us/step\n",
      "Epoch 129/300\n",
      "10/10 - 0s - loss: 0.3398 - accuracy: 0.9338 - 9ms/epoch - 900us/step\n",
      "Epoch 130/300\n",
      "10/10 - 0s - loss: 0.3367 - accuracy: 0.9369 - 9ms/epoch - 900us/step\n",
      "Epoch 131/300\n",
      "10/10 - 0s - loss: 0.3282 - accuracy: 0.9432 - 9ms/epoch - 900us/step\n",
      "Epoch 132/300\n",
      "10/10 - 0s - loss: 0.3241 - accuracy: 0.9401 - 9ms/epoch - 900us/step\n",
      "Epoch 133/300\n",
      "10/10 - 0s - loss: 0.3187 - accuracy: 0.9401 - 9ms/epoch - 900us/step\n",
      "Epoch 134/300\n",
      "10/10 - 0s - loss: 0.3239 - accuracy: 0.9401 - 8ms/epoch - 800us/step\n",
      "Epoch 135/300\n",
      "10/10 - 0s - loss: 0.3156 - accuracy: 0.9401 - 10ms/epoch - 1ms/step\n",
      "Epoch 136/300\n",
      "10/10 - 0s - loss: 0.3100 - accuracy: 0.9432 - 8ms/epoch - 800us/step\n",
      "Epoch 137/300\n",
      "10/10 - 0s - loss: 0.3102 - accuracy: 0.9401 - 9ms/epoch - 900us/step\n",
      "Epoch 138/300\n",
      "10/10 - 0s - loss: 0.3089 - accuracy: 0.9464 - 10ms/epoch - 1ms/step\n",
      "Epoch 139/300\n",
      "10/10 - 0s - loss: 0.3060 - accuracy: 0.9432 - 9ms/epoch - 900us/step\n",
      "Epoch 140/300\n",
      "10/10 - 0s - loss: 0.2973 - accuracy: 0.9464 - 10ms/epoch - 1ms/step\n",
      "Epoch 141/300\n",
      "10/10 - 0s - loss: 0.2977 - accuracy: 0.9464 - 9ms/epoch - 900us/step\n",
      "Epoch 142/300\n",
      "10/10 - 0s - loss: 0.2967 - accuracy: 0.9464 - 9ms/epoch - 900us/step\n",
      "Epoch 143/300\n",
      "10/10 - 0s - loss: 0.2866 - accuracy: 0.9495 - 10ms/epoch - 1ms/step\n",
      "Epoch 144/300\n",
      "10/10 - 0s - loss: 0.2908 - accuracy: 0.9464 - 10ms/epoch - 1ms/step\n",
      "Epoch 145/300\n",
      "10/10 - 0s - loss: 0.2802 - accuracy: 0.9464 - 10ms/epoch - 1ms/step\n",
      "Epoch 146/300\n",
      "10/10 - 0s - loss: 0.2805 - accuracy: 0.9464 - 11ms/epoch - 1ms/step\n",
      "Epoch 147/300\n",
      "10/10 - 0s - loss: 0.2809 - accuracy: 0.9432 - 9ms/epoch - 900us/step\n",
      "Epoch 148/300\n",
      "10/10 - 0s - loss: 0.2749 - accuracy: 0.9495 - 9ms/epoch - 900us/step\n",
      "Epoch 149/300\n",
      "10/10 - 0s - loss: 0.2724 - accuracy: 0.9495 - 9ms/epoch - 900us/step\n",
      "Epoch 150/300\n",
      "10/10 - 0s - loss: 0.2705 - accuracy: 0.9527 - 8ms/epoch - 800us/step\n",
      "Epoch 151/300\n",
      "10/10 - 0s - loss: 0.2666 - accuracy: 0.9495 - 9ms/epoch - 900us/step\n",
      "Epoch 152/300\n",
      "10/10 - 0s - loss: 0.2654 - accuracy: 0.9495 - 10ms/epoch - 1ms/step\n",
      "Epoch 153/300\n",
      "10/10 - 0s - loss: 0.2623 - accuracy: 0.9527 - 9ms/epoch - 900us/step\n",
      "Epoch 154/300\n",
      "10/10 - 0s - loss: 0.2567 - accuracy: 0.9495 - 9ms/epoch - 900us/step\n",
      "Epoch 155/300\n",
      "10/10 - 0s - loss: 0.2568 - accuracy: 0.9495 - 9ms/epoch - 900us/step\n",
      "Epoch 156/300\n",
      "10/10 - 0s - loss: 0.2550 - accuracy: 0.9527 - 9ms/epoch - 900us/step\n",
      "Epoch 157/300\n",
      "10/10 - 0s - loss: 0.2535 - accuracy: 0.9495 - 10ms/epoch - 1ms/step\n",
      "Epoch 158/300\n",
      "10/10 - 0s - loss: 0.2479 - accuracy: 0.9527 - 10ms/epoch - 1ms/step\n",
      "Epoch 159/300\n",
      "10/10 - 0s - loss: 0.2491 - accuracy: 0.9527 - 9ms/epoch - 900us/step\n",
      "Epoch 160/300\n",
      "10/10 - 0s - loss: 0.2472 - accuracy: 0.9527 - 10ms/epoch - 1ms/step\n",
      "Epoch 161/300\n",
      "10/10 - 0s - loss: 0.2430 - accuracy: 0.9527 - 10ms/epoch - 1ms/step\n",
      "Epoch 162/300\n",
      "10/10 - 0s - loss: 0.2409 - accuracy: 0.9495 - 10ms/epoch - 1ms/step\n",
      "Epoch 163/300\n",
      "10/10 - 0s - loss: 0.2343 - accuracy: 0.9527 - 10ms/epoch - 1ms/step\n",
      "Epoch 164/300\n",
      "10/10 - 0s - loss: 0.2340 - accuracy: 0.9495 - 10ms/epoch - 1ms/step\n",
      "Epoch 165/300\n",
      "10/10 - 0s - loss: 0.2342 - accuracy: 0.9527 - 9ms/epoch - 900us/step\n",
      "Epoch 166/300\n",
      "10/10 - 0s - loss: 0.2328 - accuracy: 0.9527 - 10ms/epoch - 1ms/step\n",
      "Epoch 167/300\n",
      "10/10 - 0s - loss: 0.2279 - accuracy: 0.9527 - 9ms/epoch - 900us/step\n",
      "Epoch 168/300\n",
      "10/10 - 0s - loss: 0.2262 - accuracy: 0.9527 - 9ms/epoch - 900us/step\n",
      "Epoch 169/300\n",
      "10/10 - 0s - loss: 0.2242 - accuracy: 0.9527 - 9ms/epoch - 900us/step\n",
      "Epoch 170/300\n",
      "10/10 - 0s - loss: 0.2190 - accuracy: 0.9527 - 9ms/epoch - 900us/step\n",
      "Epoch 171/300\n",
      "10/10 - 0s - loss: 0.2218 - accuracy: 0.9558 - 8ms/epoch - 800us/step\n",
      "Epoch 172/300\n",
      "10/10 - 0s - loss: 0.2170 - accuracy: 0.9558 - 10ms/epoch - 1ms/step\n",
      "Epoch 173/300\n",
      "10/10 - 0s - loss: 0.2176 - accuracy: 0.9527 - 8ms/epoch - 800us/step\n",
      "Epoch 174/300\n",
      "10/10 - 0s - loss: 0.2147 - accuracy: 0.9558 - 9ms/epoch - 900us/step\n",
      "Epoch 175/300\n",
      "10/10 - 0s - loss: 0.2134 - accuracy: 0.9527 - 9ms/epoch - 900us/step\n",
      "Epoch 176/300\n",
      "10/10 - 0s - loss: 0.2099 - accuracy: 0.9527 - 9ms/epoch - 900us/step\n",
      "Epoch 177/300\n",
      "10/10 - 0s - loss: 0.2045 - accuracy: 0.9558 - 9ms/epoch - 900us/step\n",
      "Epoch 178/300\n",
      "10/10 - 0s - loss: 0.2018 - accuracy: 0.9558 - 10ms/epoch - 1ms/step\n",
      "Epoch 179/300\n",
      "10/10 - 0s - loss: 0.2030 - accuracy: 0.9558 - 8ms/epoch - 800us/step\n",
      "Epoch 180/300\n",
      "10/10 - 0s - loss: 0.2035 - accuracy: 0.9558 - 9ms/epoch - 900us/step\n",
      "Epoch 181/300\n",
      "10/10 - 0s - loss: 0.1988 - accuracy: 0.9558 - 9ms/epoch - 900us/step\n",
      "Epoch 182/300\n",
      "10/10 - 0s - loss: 0.1997 - accuracy: 0.9558 - 7ms/epoch - 700us/step\n",
      "Epoch 183/300\n",
      "10/10 - 0s - loss: 0.1977 - accuracy: 0.9558 - 9ms/epoch - 900us/step\n",
      "Epoch 184/300\n",
      "10/10 - 0s - loss: 0.1951 - accuracy: 0.9558 - 10ms/epoch - 1ms/step\n",
      "Epoch 185/300\n",
      "10/10 - 0s - loss: 0.1950 - accuracy: 0.9558 - 9ms/epoch - 900us/step\n",
      "Epoch 186/300\n",
      "10/10 - 0s - loss: 0.1939 - accuracy: 0.9558 - 9ms/epoch - 900us/step\n",
      "Epoch 187/300\n",
      "10/10 - 0s - loss: 0.1898 - accuracy: 0.9590 - 9ms/epoch - 900us/step\n",
      "Epoch 188/300\n",
      "10/10 - 0s - loss: 0.1866 - accuracy: 0.9590 - 8ms/epoch - 800us/step\n",
      "Epoch 189/300\n",
      "10/10 - 0s - loss: 0.1868 - accuracy: 0.9590 - 10ms/epoch - 1ms/step\n",
      "Epoch 190/300\n",
      "10/10 - 0s - loss: 0.1857 - accuracy: 0.9558 - 9ms/epoch - 900us/step\n",
      "Epoch 191/300\n",
      "10/10 - 0s - loss: 0.1833 - accuracy: 0.9590 - 11ms/epoch - 1ms/step\n",
      "Epoch 192/300\n",
      "10/10 - 0s - loss: 0.1834 - accuracy: 0.9590 - 8ms/epoch - 800us/step\n",
      "Epoch 193/300\n",
      "10/10 - 0s - loss: 0.1833 - accuracy: 0.9590 - 12ms/epoch - 1ms/step\n",
      "Epoch 194/300\n",
      "10/10 - 0s - loss: 0.1790 - accuracy: 0.9590 - 9ms/epoch - 900us/step\n",
      "Epoch 195/300\n",
      "10/10 - 0s - loss: 0.1741 - accuracy: 0.9590 - 10ms/epoch - 1ms/step\n",
      "Epoch 196/300\n",
      "10/10 - 0s - loss: 0.1759 - accuracy: 0.9590 - 9ms/epoch - 900us/step\n",
      "Epoch 197/300\n",
      "10/10 - 0s - loss: 0.1779 - accuracy: 0.9621 - 9ms/epoch - 900us/step\n",
      "Epoch 198/300\n",
      "10/10 - 0s - loss: 0.1717 - accuracy: 0.9621 - 8ms/epoch - 800us/step\n",
      "Epoch 199/300\n",
      "10/10 - 0s - loss: 0.1722 - accuracy: 0.9621 - 9ms/epoch - 900us/step\n",
      "Epoch 200/300\n",
      "10/10 - 0s - loss: 0.1709 - accuracy: 0.9621 - 10ms/epoch - 1ms/step\n",
      "Epoch 201/300\n",
      "10/10 - 0s - loss: 0.1688 - accuracy: 0.9685 - 8ms/epoch - 800us/step\n",
      "Epoch 202/300\n",
      "10/10 - 0s - loss: 0.1664 - accuracy: 0.9621 - 9ms/epoch - 900us/step\n",
      "Epoch 203/300\n",
      "10/10 - 0s - loss: 0.1628 - accuracy: 0.9621 - 10ms/epoch - 1ms/step\n",
      "Epoch 204/300\n",
      "10/10 - 0s - loss: 0.1641 - accuracy: 0.9653 - 10ms/epoch - 1ms/step\n",
      "Epoch 205/300\n",
      "10/10 - 0s - loss: 0.1626 - accuracy: 0.9621 - 8ms/epoch - 800us/step\n",
      "Epoch 206/300\n",
      "10/10 - 0s - loss: 0.1612 - accuracy: 0.9590 - 9ms/epoch - 900us/step\n",
      "Epoch 207/300\n",
      "10/10 - 0s - loss: 0.1613 - accuracy: 0.9621 - 9ms/epoch - 900us/step\n",
      "Epoch 208/300\n",
      "10/10 - 0s - loss: 0.1581 - accuracy: 0.9653 - 9ms/epoch - 900us/step\n",
      "Epoch 209/300\n",
      "10/10 - 0s - loss: 0.1572 - accuracy: 0.9653 - 8ms/epoch - 800us/step\n",
      "Epoch 210/300\n",
      "10/10 - 0s - loss: 0.1554 - accuracy: 0.9653 - 9ms/epoch - 900us/step\n",
      "Epoch 211/300\n",
      "10/10 - 0s - loss: 0.1560 - accuracy: 0.9653 - 10ms/epoch - 1ms/step\n",
      "Epoch 212/300\n",
      "10/10 - 0s - loss: 0.1526 - accuracy: 0.9653 - 9ms/epoch - 900us/step\n",
      "Epoch 213/300\n",
      "10/10 - 0s - loss: 0.1536 - accuracy: 0.9653 - 9ms/epoch - 900us/step\n",
      "Epoch 214/300\n",
      "10/10 - 0s - loss: 0.1491 - accuracy: 0.9621 - 9ms/epoch - 900us/step\n",
      "Epoch 215/300\n",
      "10/10 - 0s - loss: 0.1516 - accuracy: 0.9685 - 9ms/epoch - 900us/step\n",
      "Epoch 216/300\n",
      "10/10 - 0s - loss: 0.1513 - accuracy: 0.9653 - 10ms/epoch - 1ms/step\n",
      "Epoch 217/300\n",
      "10/10 - 0s - loss: 0.1483 - accuracy: 0.9653 - 8ms/epoch - 800us/step\n",
      "Epoch 218/300\n",
      "10/10 - 0s - loss: 0.1424 - accuracy: 0.9653 - 9ms/epoch - 900us/step\n",
      "Epoch 219/300\n",
      "10/10 - 0s - loss: 0.1456 - accuracy: 0.9653 - 10ms/epoch - 1ms/step\n",
      "Epoch 220/300\n",
      "10/10 - 0s - loss: 0.1451 - accuracy: 0.9653 - 10ms/epoch - 1ms/step\n",
      "Epoch 221/300\n",
      "10/10 - 0s - loss: 0.1445 - accuracy: 0.9653 - 9ms/epoch - 900us/step\n",
      "Epoch 222/300\n",
      "10/10 - 0s - loss: 0.1428 - accuracy: 0.9653 - 10ms/epoch - 961us/step\n",
      "Epoch 223/300\n",
      "10/10 - 0s - loss: 0.1394 - accuracy: 0.9653 - 9ms/epoch - 900us/step\n",
      "Epoch 224/300\n",
      "10/10 - 0s - loss: 0.1375 - accuracy: 0.9685 - 10ms/epoch - 1ms/step\n",
      "Epoch 225/300\n",
      "10/10 - 0s - loss: 0.1385 - accuracy: 0.9716 - 9ms/epoch - 900us/step\n",
      "Epoch 226/300\n",
      "10/10 - 0s - loss: 0.1363 - accuracy: 0.9653 - 9ms/epoch - 900us/step\n",
      "Epoch 227/300\n",
      "10/10 - 0s - loss: 0.1387 - accuracy: 0.9653 - 10ms/epoch - 1ms/step\n",
      "Epoch 228/300\n",
      "10/10 - 0s - loss: 0.1318 - accuracy: 0.9685 - 10ms/epoch - 1ms/step\n",
      "Epoch 229/300\n",
      "10/10 - 0s - loss: 0.1303 - accuracy: 0.9685 - 9ms/epoch - 900us/step\n",
      "Epoch 230/300\n",
      "10/10 - 0s - loss: 0.1310 - accuracy: 0.9716 - 9ms/epoch - 900us/step\n",
      "Epoch 231/300\n",
      "10/10 - 0s - loss: 0.1323 - accuracy: 0.9653 - 9ms/epoch - 900us/step\n",
      "Epoch 232/300\n",
      "10/10 - 0s - loss: 0.1321 - accuracy: 0.9653 - 9ms/epoch - 900us/step\n",
      "Epoch 233/300\n",
      "10/10 - 0s - loss: 0.1320 - accuracy: 0.9716 - 10ms/epoch - 1ms/step\n",
      "Epoch 234/300\n",
      "10/10 - 0s - loss: 0.1283 - accuracy: 0.9653 - 10ms/epoch - 1ms/step\n",
      "Epoch 235/300\n",
      "10/10 - 0s - loss: 0.1304 - accuracy: 0.9716 - 9ms/epoch - 900us/step\n",
      "Epoch 236/300\n",
      "10/10 - 0s - loss: 0.1275 - accuracy: 0.9748 - 9ms/epoch - 900us/step\n",
      "Epoch 237/300\n",
      "10/10 - 0s - loss: 0.1269 - accuracy: 0.9653 - 10ms/epoch - 1ms/step\n",
      "Epoch 238/300\n",
      "10/10 - 0s - loss: 0.1258 - accuracy: 0.9653 - 12ms/epoch - 1ms/step\n",
      "Epoch 239/300\n",
      "10/10 - 0s - loss: 0.1237 - accuracy: 0.9779 - 9ms/epoch - 900us/step\n",
      "Epoch 240/300\n",
      "10/10 - 0s - loss: 0.1212 - accuracy: 0.9779 - 10ms/epoch - 1ms/step\n",
      "Epoch 241/300\n",
      "10/10 - 0s - loss: 0.1233 - accuracy: 0.9653 - 11ms/epoch - 1ms/step\n",
      "Epoch 242/300\n",
      "10/10 - 0s - loss: 0.1222 - accuracy: 0.9716 - 10ms/epoch - 1ms/step\n",
      "Epoch 243/300\n",
      "10/10 - 0s - loss: 0.1220 - accuracy: 0.9779 - 9ms/epoch - 900us/step\n",
      "Epoch 244/300\n",
      "10/10 - 0s - loss: 0.1199 - accuracy: 0.9811 - 9ms/epoch - 900us/step\n",
      "Epoch 245/300\n",
      "10/10 - 0s - loss: 0.1186 - accuracy: 0.9811 - 10ms/epoch - 1ms/step\n",
      "Epoch 246/300\n",
      "10/10 - 0s - loss: 0.1183 - accuracy: 0.9811 - 10ms/epoch - 1ms/step\n",
      "Epoch 247/300\n",
      "10/10 - 0s - loss: 0.1177 - accuracy: 0.9716 - 9ms/epoch - 900us/step\n",
      "Epoch 248/300\n",
      "10/10 - 0s - loss: 0.1158 - accuracy: 0.9811 - 10ms/epoch - 1ms/step\n",
      "Epoch 249/300\n",
      "10/10 - 0s - loss: 0.1175 - accuracy: 0.9779 - 10ms/epoch - 1ms/step\n",
      "Epoch 250/300\n",
      "10/10 - 0s - loss: 0.1128 - accuracy: 0.9811 - 10ms/epoch - 1ms/step\n",
      "Epoch 251/300\n",
      "10/10 - 0s - loss: 0.1138 - accuracy: 0.9779 - 8ms/epoch - 800us/step\n",
      "Epoch 252/300\n",
      "10/10 - 0s - loss: 0.1100 - accuracy: 0.9779 - 9ms/epoch - 900us/step\n",
      "Epoch 253/300\n",
      "10/10 - 0s - loss: 0.1131 - accuracy: 0.9685 - 8ms/epoch - 800us/step\n",
      "Epoch 254/300\n",
      "10/10 - 0s - loss: 0.1112 - accuracy: 0.9811 - 10ms/epoch - 1ms/step\n",
      "Epoch 255/300\n",
      "10/10 - 0s - loss: 0.1089 - accuracy: 0.9811 - 9ms/epoch - 900us/step\n",
      "Epoch 256/300\n",
      "10/10 - 0s - loss: 0.1073 - accuracy: 0.9811 - 8ms/epoch - 800us/step\n",
      "Epoch 257/300\n",
      "10/10 - 0s - loss: 0.1113 - accuracy: 0.9811 - 9ms/epoch - 900us/step\n",
      "Epoch 258/300\n",
      "10/10 - 0s - loss: 0.1102 - accuracy: 0.9811 - 9ms/epoch - 900us/step\n",
      "Epoch 259/300\n",
      "10/10 - 0s - loss: 0.1060 - accuracy: 0.9811 - 9ms/epoch - 900us/step\n",
      "Epoch 260/300\n",
      "10/10 - 0s - loss: 0.1045 - accuracy: 0.9811 - 9ms/epoch - 900us/step\n",
      "Epoch 261/300\n",
      "10/10 - 0s - loss: 0.1073 - accuracy: 0.9811 - 9ms/epoch - 900us/step\n",
      "Epoch 262/300\n",
      "10/10 - 0s - loss: 0.1068 - accuracy: 0.9811 - 9ms/epoch - 900us/step\n",
      "Epoch 263/300\n",
      "10/10 - 0s - loss: 0.1023 - accuracy: 0.9811 - 9ms/epoch - 900us/step\n",
      "Epoch 264/300\n",
      "10/10 - 0s - loss: 0.1034 - accuracy: 0.9842 - 9ms/epoch - 900us/step\n",
      "Epoch 265/300\n",
      "10/10 - 0s - loss: 0.1011 - accuracy: 0.9842 - 8ms/epoch - 800us/step\n",
      "Epoch 266/300\n",
      "10/10 - 0s - loss: 0.1035 - accuracy: 0.9811 - 9ms/epoch - 900us/step\n",
      "Epoch 267/300\n",
      "10/10 - 0s - loss: 0.1002 - accuracy: 0.9874 - 9ms/epoch - 900us/step\n",
      "Epoch 268/300\n",
      "10/10 - 0s - loss: 0.1022 - accuracy: 0.9874 - 9ms/epoch - 900us/step\n",
      "Epoch 269/300\n",
      "10/10 - 0s - loss: 0.1008 - accuracy: 0.9874 - 10ms/epoch - 1ms/step\n",
      "Epoch 270/300\n",
      "10/10 - 0s - loss: 0.1012 - accuracy: 0.9842 - 9ms/epoch - 900us/step\n",
      "Epoch 271/300\n",
      "10/10 - 0s - loss: 0.0989 - accuracy: 0.9874 - 9ms/epoch - 900us/step\n",
      "Epoch 272/300\n",
      "10/10 - 0s - loss: 0.0982 - accuracy: 0.9874 - 10ms/epoch - 1ms/step\n",
      "Epoch 273/300\n",
      "10/10 - 0s - loss: 0.0985 - accuracy: 0.9842 - 10ms/epoch - 1ms/step\n",
      "Epoch 274/300\n",
      "10/10 - 0s - loss: 0.0978 - accuracy: 0.9905 - 9ms/epoch - 900us/step\n",
      "Epoch 275/300\n",
      "10/10 - 0s - loss: 0.0986 - accuracy: 0.9874 - 10ms/epoch - 1ms/step\n",
      "Epoch 276/300\n",
      "10/10 - 0s - loss: 0.0935 - accuracy: 0.9905 - 10ms/epoch - 1ms/step\n",
      "Epoch 277/300\n",
      "10/10 - 0s - loss: 0.0960 - accuracy: 0.9842 - 9ms/epoch - 900us/step\n",
      "Epoch 278/300\n",
      "10/10 - 0s - loss: 0.0928 - accuracy: 0.9874 - 10ms/epoch - 1ms/step\n",
      "Epoch 279/300\n",
      "10/10 - 0s - loss: 0.0941 - accuracy: 0.9874 - 9ms/epoch - 900us/step\n",
      "Epoch 280/300\n",
      "10/10 - 0s - loss: 0.0920 - accuracy: 0.9874 - 10ms/epoch - 1ms/step\n",
      "Epoch 281/300\n",
      "10/10 - 0s - loss: 0.0919 - accuracy: 0.9874 - 9ms/epoch - 900us/step\n",
      "Epoch 282/300\n",
      "10/10 - 0s - loss: 0.0882 - accuracy: 0.9874 - 8ms/epoch - 800us/step\n",
      "Epoch 283/300\n",
      "10/10 - 0s - loss: 0.0905 - accuracy: 0.9874 - 9ms/epoch - 900us/step\n",
      "Epoch 284/300\n",
      "10/10 - 0s - loss: 0.0903 - accuracy: 0.9905 - 9ms/epoch - 900us/step\n",
      "Epoch 285/300\n",
      "10/10 - 0s - loss: 0.0907 - accuracy: 0.9874 - 10ms/epoch - 1ms/step\n",
      "Epoch 286/300\n",
      "10/10 - 0s - loss: 0.0888 - accuracy: 0.9905 - 11ms/epoch - 1ms/step\n",
      "Epoch 287/300\n",
      "10/10 - 0s - loss: 0.0859 - accuracy: 0.9874 - 10ms/epoch - 1ms/step\n",
      "Epoch 288/300\n",
      "10/10 - 0s - loss: 0.0894 - accuracy: 0.9874 - 9ms/epoch - 900us/step\n",
      "Epoch 289/300\n",
      "10/10 - 0s - loss: 0.0882 - accuracy: 0.9874 - 10ms/epoch - 1ms/step\n",
      "Epoch 290/300\n",
      "10/10 - 0s - loss: 0.0866 - accuracy: 0.9905 - 10ms/epoch - 1ms/step\n",
      "Epoch 291/300\n",
      "10/10 - 0s - loss: 0.0883 - accuracy: 0.9842 - 10ms/epoch - 1ms/step\n",
      "Epoch 292/300\n",
      "10/10 - 0s - loss: 0.0841 - accuracy: 0.9874 - 8ms/epoch - 800us/step\n",
      "Epoch 293/300\n",
      "10/10 - 0s - loss: 0.0863 - accuracy: 0.9874 - 9ms/epoch - 900us/step\n",
      "Epoch 294/300\n",
      "10/10 - 0s - loss: 0.0841 - accuracy: 0.9905 - 11ms/epoch - 1ms/step\n",
      "Epoch 295/300\n",
      "10/10 - 0s - loss: 0.0848 - accuracy: 0.9874 - 10ms/epoch - 1ms/step\n",
      "Epoch 296/300\n",
      "10/10 - 0s - loss: 0.0840 - accuracy: 0.9874 - 9ms/epoch - 900us/step\n",
      "Epoch 297/300\n",
      "10/10 - 0s - loss: 0.0847 - accuracy: 0.9874 - 8ms/epoch - 800us/step\n",
      "Epoch 298/300\n",
      "10/10 - 0s - loss: 0.0846 - accuracy: 0.9874 - 10ms/epoch - 1ms/step\n",
      "Epoch 299/300\n",
      "10/10 - 0s - loss: 0.0836 - accuracy: 0.9905 - 14ms/epoch - 1ms/step\n",
      "Epoch 300/300\n",
      "10/10 - 0s - loss: 0.0781 - accuracy: 0.9874 - 10ms/epoch - 1ms/step\n",
      "10/10 [==============================] - 0s 10ms/step - loss: 1.8933 - accuracy: 0.4763\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "'\\n\\n'"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "## https://www.youtube.com/watch?v=NoKvCREx36Q\n",
    "import os\n",
    "from posixpath import split \n",
    "os.environ[\"TF_CPP_MIN_LOG_LEVEL\"] = '2'\n",
    "import tensorflow as tf\n",
    "import pandas as pd\n",
    "import tensorflow_datasets as tfds\n",
    "from tensorflow import keras\n",
    "from tensorflow.keras import layers\n",
    "import pickle\n",
    "\n",
    "ds_train = tf.data.TextLineDataset(\"emotions_train.csv\")\n",
    "ds_test = tf.data.TextLineDataset(\"emotions_test.csv\")\n",
    "\n",
    "def filter_train(line):\n",
    "    split_line = tf.strings.split(line, \",\", maxsplit=1)\n",
    "    sentiment_category = split_line[1] # \n",
    "\n",
    "    return (\n",
    "        True\n",
    "        if sentiment_category != None\n",
    "        else False\n",
    "    )\n",
    "\n",
    "# for line in ds_train.skip(1).take(5):\n",
    "#     print(tf.strings.split(line, \",\", maxsplit=2))\n",
    "\n",
    "tokenizer = tfds.deprecated.text.Tokenizer()\n",
    "\n",
    "def build_vocabulary(ds_train, threshold=10):\n",
    "    \"\"\" Build a vocabulary \"\"\"\n",
    "    frequencies = {}\n",
    "    vocabulary = set()\n",
    "    vocabulary.update([\"sostoken\"])\n",
    "    vocabulary.update([\"eostoken\"])\n",
    "\n",
    "    for line in ds_train.skip(1):\n",
    "        split_line = tf.strings.split(line, \",\", maxsplit=2)\n",
    "        review = split_line[2]\n",
    "        tokenized_text = tokenizer.tokenize(review.numpy().lower())\n",
    "\n",
    "        for word in tokenized_text:\n",
    "            if word not in frequencies:\n",
    "                frequencies[word] = 1\n",
    "            else:\n",
    "                frequencies[word] += 1\n",
    "\n",
    "            # if we've reached the threshold\n",
    "            if frequencies[word] == threshold:\n",
    "                vocabulary.update(tokenized_text)\n",
    "\n",
    "    return vocabulary\n",
    "\n",
    "# Build vocabulary and save it to vocabulary.obj\n",
    "vocabulary = build_vocabulary(ds_train)\n",
    "vocab_file = open(\"vocabulary.obj\", \"wb\")\n",
    "pickle.dump(vocabulary, vocab_file)\n",
    "\n",
    "# Loading the vocabulary\n",
    "# vocab_file = open(\"vocabulary.obj\", \"rb\")\n",
    "# vocabulary = pickle.load(vocab_file)\n",
    "\n",
    "encoder = tfds.deprecated.text.TokenTextEncoder(\n",
    "    list(vocabulary), oov_token=\"<UNK>\", lowercase=True, tokenizer=tokenizer,\n",
    ")\n",
    "\n",
    "def my_encoder(text_tensor, label):\n",
    "    encoded_text = encoder.encode(text_tensor.numpy())\n",
    "    return encoded_text, label\n",
    "\n",
    "def encode_map_fn(line):\n",
    "    split_line = tf.strings.split(line, \",\", maxsplit=4)\n",
    "    label_str = split_line[1]  # neg, pos\n",
    "    review = \"sostoken \" + split_line[2] + \" eostoken\"\n",
    "    label = 0\n",
    "\n",
    "    if label_str == \"joy\":\n",
    "        label = 0\n",
    "    elif label_str == \"sadness\":\n",
    "        label = 1\n",
    "    elif label_str == \"fear\":\n",
    "        label = 2\n",
    "    elif label_str == \"anger\":\n",
    "        label = 3\n",
    "\n",
    "    (encoded_text, label) = tf.py_function(\n",
    "        my_encoder, inp=[review, label], Tout=(tf.int64, tf.int32),\n",
    "    )\n",
    "\n",
    "    encoded_text.set_shape([None])\n",
    "    label.set_shape([])\n",
    "    return encoded_text, label\n",
    "\n",
    "AUTOTUNE = tf.data.experimental.AUTOTUNE\n",
    "ds_train = ds_train.map(encode_map_fn, num_parallel_calls=AUTOTUNE).cache()\n",
    "ds_train = ds_train.shuffle(25000)\n",
    "ds_train = ds_train.padded_batch(32, padded_shapes=([None], ()))\n",
    "\n",
    "ds_test = ds_test.map(encode_map_fn)\n",
    "ds_test = ds_test.padded_batch(32, padded_shapes=([None], ()))\n",
    "\n",
    "model = keras.Sequential(\n",
    "    [\n",
    "        layers.Masking(mask_value=0),\n",
    "        layers.Embedding(input_dim=len(vocabulary) + 2, output_dim=32,),\n",
    "        layers.GlobalAveragePooling1D(),\n",
    "        layers.Dense(64, activation=\"relu\"),\n",
    "        layers.Dense(4, activation=\"softmax\"),\n",
    "    ]\n",
    ")\n",
    "\n",
    "model.compile(\n",
    "    loss=keras.losses.SparseCategoricalCrossentropy(from_logits=True),\n",
    "    optimizer=keras.optimizers.Adam(3e-4, clipnorm=1),\n",
    "    metrics=[\"accuracy\"],\n",
    ")\n",
    "\n",
    "model.fit(ds_train, epochs=300, verbose=2)\n",
    "model.evaluate(ds_test)\n",
    "\n",
    "\n",
    "'''\n",
    "\n",
    "'''\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "prediction shape:  [[9.7137883e-02 4.4755888e-01 2.2566977e-01 2.2963345e-01]\n",
      " [3.9265715e-13 8.1258351e-09 9.9971992e-01 2.8008225e-04]]\n"
     ]
    }
   ],
   "source": [
    "test = tf.data.TextLineDataset(\"hope.csv\")\n",
    "test = test.map(encode_map_fn)\n",
    "test = test.padded_batch(32, padded_shapes=([None], ()))\n",
    "\n",
    "\n",
    "prediction = model.predict(test)\n",
    "print(\"prediction shape: \", prediction)\n",
    "\n",
    "\n"
   ]
  }
 ],
 "metadata": {
  "interpreter": {
   "hash": "acfd08a7faa67adda30a139a14258a4609e125be16bd9d56539cb9e1d9f3c0a6"
  },
  "kernelspec": {
   "display_name": "Python 3.10.4 64-bit",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.4"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
