{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Imports\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Function"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "def getLabel(label):\n",
    "    # numerical mapping of the labels\n",
    "    if label == str.encode(\"joy\"):\n",
    "        return 0\n",
    "    elif label == str.encode(\"sadness\"):\n",
    "        return 1\n",
    "    elif label == str.encode(\"fear\"):\n",
    "        return 2\n",
    "    elif label == str.encode(\"anger\"):\n",
    "        return 3\n",
    "\n",
    "\n",
    "def save_model(model, filename):\n",
    "    model.save(filename)\n",
    "\n",
    "\n",
    "def load_model(filename):\n",
    "    return tf.keras.models.load_model(filename)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Load Data\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "b'Just got back from seeing @GaryDelaney in Burslem. AMAZING!! Face still hurts from laughing so much #hilarious'\n",
      "0\n",
      "b'OMG NOL i love u so so much i love ur cheery face and hugs \\xf0\\x9f\\x98\\x98\\xf0\\x9f\\x98\\x98\\xf0\\x9f\\x98\\x98 @CRAZYmac17'\n",
      "0\n"
     ]
    }
   ],
   "source": [
    "# Open training data\n",
    "train_dataset = tf.data.TextLineDataset(\"emotions_train.csv\").skip(1)\n",
    "test_dataset = tf.data.TextLineDataset(\"emotions_test.csv\").skip(1)\n",
    "\n",
    "x_train = []\n",
    "y_train = []\n",
    "\n",
    "# Formatting data for the network\n",
    "for line in train_dataset:\n",
    "    split_line = tf.strings.split(line, \",\", maxsplit=2)\n",
    "    x_train.append(split_line[2].numpy())\n",
    "    y_train.append(getLabel(split_line[1].numpy()))\n",
    "\n",
    "x_train = np.asarray(x_train)\n",
    "y_train = np.asarray(y_train)\n",
    "\n",
    "print(x_train[0])\n",
    "print(y_train[0])\n",
    "\n",
    "x_test = []\n",
    "y_test = []\n",
    "\n",
    "# Formatting data for the network\n",
    "for line in test_dataset:\n",
    "    split_line = tf.strings.split(line, \",\", maxsplit=2)\n",
    "    x_test.append(split_line[2].numpy())\n",
    "    y_test.append(getLabel(split_line[1].numpy()))\n",
    "\n",
    "x_test = np.asarray(x_test)\n",
    "y_test = np.asarray(y_test)\n",
    "\n",
    "print(x_test[0])\n",
    "print(y_test[0])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Manipulate Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Convert strings to arrays of numbers\n",
    "max_words = 1000\n",
    "vectorize_layer = tf.keras.layers.TextVectorization(\n",
    "    max_tokens=max_words)\n",
    "\n",
    "vectorize_layer.adapt(x_train)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Training\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/100\n",
      "17/17 [==============================] - 1s 23ms/step - loss: 1.4026 - accuracy: 0.2081 - val_loss: 1.3967 - val_accuracy: 0.2255\n",
      "Epoch 2/100\n",
      "17/17 [==============================] - 0s 11ms/step - loss: 1.3865 - accuracy: 0.2435 - val_loss: 1.3934 - val_accuracy: 0.2226\n",
      "Epoch 3/100\n",
      "17/17 [==============================] - 0s 11ms/step - loss: 1.3736 - accuracy: 0.2905 - val_loss: 1.3900 - val_accuracy: 0.2275\n",
      "Epoch 4/100\n",
      "17/17 [==============================] - 0s 11ms/step - loss: 1.3608 - accuracy: 0.3423 - val_loss: 1.3869 - val_accuracy: 0.2631\n",
      "Epoch 5/100\n",
      "17/17 [==============================] - 0s 12ms/step - loss: 1.3480 - accuracy: 0.4027 - val_loss: 1.3836 - val_accuracy: 0.2710\n",
      "Epoch 6/100\n",
      "17/17 [==============================] - 0s 11ms/step - loss: 1.3342 - accuracy: 0.4449 - val_loss: 1.3820 - val_accuracy: 0.2839\n",
      "Epoch 7/100\n",
      "17/17 [==============================] - 0s 11ms/step - loss: 1.3201 - accuracy: 0.4784 - val_loss: 1.3805 - val_accuracy: 0.3007\n",
      "Epoch 8/100\n",
      "17/17 [==============================] - 0s 11ms/step - loss: 1.3042 - accuracy: 0.5034 - val_loss: 1.3791 - val_accuracy: 0.3116\n",
      "Epoch 9/100\n",
      "17/17 [==============================] - 0s 11ms/step - loss: 1.2866 - accuracy: 0.5197 - val_loss: 1.3781 - val_accuracy: 0.3165\n",
      "Epoch 10/100\n",
      "17/17 [==============================] - 0s 11ms/step - loss: 1.2667 - accuracy: 0.5407 - val_loss: 1.3776 - val_accuracy: 0.3165\n",
      "Epoch 11/100\n",
      "17/17 [==============================] - 0s 12ms/step - loss: 1.2420 - accuracy: 0.5427 - val_loss: 1.3777 - val_accuracy: 0.3215\n",
      "Epoch 12/100\n",
      "17/17 [==============================] - 0s 11ms/step - loss: 1.2131 - accuracy: 0.5743 - val_loss: 1.3773 - val_accuracy: 0.3234\n",
      "Epoch 13/100\n",
      "17/17 [==============================] - 0s 11ms/step - loss: 1.1779 - accuracy: 0.5820 - val_loss: 1.3772 - val_accuracy: 0.3284\n",
      "Epoch 14/100\n",
      "17/17 [==============================] - 0s 11ms/step - loss: 1.1331 - accuracy: 0.6222 - val_loss: 1.3773 - val_accuracy: 0.3225\n",
      "Epoch 15/100\n",
      "17/17 [==============================] - 0s 11ms/step - loss: 1.0799 - accuracy: 0.6414 - val_loss: 1.3762 - val_accuracy: 0.3442\n",
      "Epoch 16/100\n",
      "17/17 [==============================] - 0s 11ms/step - loss: 1.0327 - accuracy: 0.6894 - val_loss: 1.3749 - val_accuracy: 0.3591\n",
      "Epoch 17/100\n",
      "17/17 [==============================] - 0s 11ms/step - loss: 0.9664 - accuracy: 0.7133 - val_loss: 1.3833 - val_accuracy: 0.3699\n",
      "Epoch 18/100\n",
      "17/17 [==============================] - 0s 11ms/step - loss: 0.9046 - accuracy: 0.7181 - val_loss: 1.3804 - val_accuracy: 0.3680\n",
      "Epoch 19/100\n",
      "17/17 [==============================] - 0s 11ms/step - loss: 0.8415 - accuracy: 0.7536 - val_loss: 1.3916 - val_accuracy: 0.3828\n",
      "Epoch 20/100\n",
      "17/17 [==============================] - 0s 12ms/step - loss: 0.7842 - accuracy: 0.7929 - val_loss: 1.4015 - val_accuracy: 0.3907\n",
      "Epoch 21/100\n",
      "17/17 [==============================] - 0s 11ms/step - loss: 0.7260 - accuracy: 0.8130 - val_loss: 1.3870 - val_accuracy: 0.3798\n",
      "Epoch 22/100\n",
      "17/17 [==============================] - 0s 11ms/step - loss: 0.6720 - accuracy: 0.8437 - val_loss: 1.3997 - val_accuracy: 0.3887\n",
      "Epoch 23/100\n",
      "17/17 [==============================] - 0s 12ms/step - loss: 0.6156 - accuracy: 0.8629 - val_loss: 1.4128 - val_accuracy: 0.3828\n",
      "Epoch 24/100\n",
      "17/17 [==============================] - 0s 12ms/step - loss: 0.5718 - accuracy: 0.8734 - val_loss: 1.4285 - val_accuracy: 0.3877\n",
      "Epoch 25/100\n",
      "17/17 [==============================] - 0s 12ms/step - loss: 0.5227 - accuracy: 0.9032 - val_loss: 1.4332 - val_accuracy: 0.4026\n",
      "Epoch 26/100\n",
      "17/17 [==============================] - 0s 11ms/step - loss: 0.4791 - accuracy: 0.9166 - val_loss: 1.4302 - val_accuracy: 0.4095\n",
      "Epoch 27/100\n",
      "17/17 [==============================] - 0s 12ms/step - loss: 0.4382 - accuracy: 0.9271 - val_loss: 1.4662 - val_accuracy: 0.4135\n",
      "Epoch 28/100\n",
      "17/17 [==============================] - 0s 11ms/step - loss: 0.3988 - accuracy: 0.9415 - val_loss: 1.4824 - val_accuracy: 0.4233\n",
      "Epoch 29/100\n",
      "17/17 [==============================] - 0s 12ms/step - loss: 0.3678 - accuracy: 0.9425 - val_loss: 1.5036 - val_accuracy: 0.4184\n",
      "Epoch 30/100\n",
      "17/17 [==============================] - 0s 11ms/step - loss: 0.3380 - accuracy: 0.9482 - val_loss: 1.5231 - val_accuracy: 0.4342\n",
      "Epoch 31/100\n",
      "17/17 [==============================] - 0s 11ms/step - loss: 0.3105 - accuracy: 0.9549 - val_loss: 1.5619 - val_accuracy: 0.4342\n",
      "Epoch 32/100\n",
      "17/17 [==============================] - 0s 12ms/step - loss: 0.2896 - accuracy: 0.9511 - val_loss: 1.5705 - val_accuracy: 0.4332\n",
      "Epoch 33/100\n",
      "17/17 [==============================] - 0s 12ms/step - loss: 0.2665 - accuracy: 0.9674 - val_loss: 1.6038 - val_accuracy: 0.4372\n",
      "Epoch 34/100\n",
      "17/17 [==============================] - 0s 11ms/step - loss: 0.2501 - accuracy: 0.9684 - val_loss: 1.6170 - val_accuracy: 0.4332\n",
      "Epoch 35/100\n",
      "17/17 [==============================] - 0s 11ms/step - loss: 0.2308 - accuracy: 0.9712 - val_loss: 1.6518 - val_accuracy: 0.4372\n",
      "Epoch 36/100\n",
      "17/17 [==============================] - 0s 11ms/step - loss: 0.2146 - accuracy: 0.9712 - val_loss: 1.6740 - val_accuracy: 0.4352\n",
      "Epoch 37/100\n",
      "17/17 [==============================] - 0s 12ms/step - loss: 0.2002 - accuracy: 0.9722 - val_loss: 1.7030 - val_accuracy: 0.4382\n",
      "Epoch 38/100\n",
      "17/17 [==============================] - 0s 12ms/step - loss: 0.1876 - accuracy: 0.9741 - val_loss: 1.7296 - val_accuracy: 0.4342\n",
      "Epoch 39/100\n",
      "17/17 [==============================] - 0s 11ms/step - loss: 0.1773 - accuracy: 0.9741 - val_loss: 1.7539 - val_accuracy: 0.4402\n",
      "Epoch 40/100\n",
      "17/17 [==============================] - 0s 12ms/step - loss: 0.1679 - accuracy: 0.9789 - val_loss: 1.7815 - val_accuracy: 0.4372\n",
      "Epoch 41/100\n",
      "17/17 [==============================] - 0s 11ms/step - loss: 0.1585 - accuracy: 0.9751 - val_loss: 1.8175 - val_accuracy: 0.4402\n",
      "Epoch 42/100\n",
      "17/17 [==============================] - 0s 11ms/step - loss: 0.1516 - accuracy: 0.9779 - val_loss: 1.8445 - val_accuracy: 0.4362\n",
      "Epoch 43/100\n",
      "17/17 [==============================] - 0s 12ms/step - loss: 0.1429 - accuracy: 0.9799 - val_loss: 1.8712 - val_accuracy: 0.4421\n",
      "Epoch 44/100\n",
      "17/17 [==============================] - 0s 11ms/step - loss: 0.1361 - accuracy: 0.9799 - val_loss: 1.8969 - val_accuracy: 0.4322\n",
      "Epoch 45/100\n",
      "17/17 [==============================] - 0s 11ms/step - loss: 0.1327 - accuracy: 0.9789 - val_loss: 1.9073 - val_accuracy: 0.4362\n",
      "Epoch 46/100\n",
      "17/17 [==============================] - 0s 11ms/step - loss: 0.1261 - accuracy: 0.9808 - val_loss: 1.9339 - val_accuracy: 0.4372\n",
      "Epoch 47/100\n",
      "17/17 [==============================] - 0s 11ms/step - loss: 0.1204 - accuracy: 0.9808 - val_loss: 1.9730 - val_accuracy: 0.4332\n",
      "Epoch 48/100\n",
      "17/17 [==============================] - 0s 12ms/step - loss: 0.1150 - accuracy: 0.9818 - val_loss: 1.9893 - val_accuracy: 0.4303\n",
      "Epoch 49/100\n",
      "17/17 [==============================] - 0s 11ms/step - loss: 0.1109 - accuracy: 0.9837 - val_loss: 2.0022 - val_accuracy: 0.4372\n",
      "Epoch 50/100\n",
      "17/17 [==============================] - 0s 11ms/step - loss: 0.1064 - accuracy: 0.9837 - val_loss: 2.0300 - val_accuracy: 0.4441\n",
      "Epoch 51/100\n",
      "17/17 [==============================] - 0s 11ms/step - loss: 0.1020 - accuracy: 0.9847 - val_loss: 2.0579 - val_accuracy: 0.4342\n",
      "Epoch 52/100\n",
      "17/17 [==============================] - 0s 12ms/step - loss: 0.0988 - accuracy: 0.9856 - val_loss: 2.0667 - val_accuracy: 0.4402\n",
      "Epoch 53/100\n",
      "17/17 [==============================] - 0s 11ms/step - loss: 0.0932 - accuracy: 0.9875 - val_loss: 2.0962 - val_accuracy: 0.4372\n",
      "Epoch 54/100\n",
      "17/17 [==============================] - 0s 12ms/step - loss: 0.0920 - accuracy: 0.9856 - val_loss: 2.1160 - val_accuracy: 0.4372\n",
      "Epoch 55/100\n",
      "17/17 [==============================] - 0s 12ms/step - loss: 0.0880 - accuracy: 0.9875 - val_loss: 2.1185 - val_accuracy: 0.4392\n",
      "Epoch 56/100\n",
      "17/17 [==============================] - 0s 12ms/step - loss: 0.0868 - accuracy: 0.9866 - val_loss: 2.1520 - val_accuracy: 0.4411\n",
      "Epoch 57/100\n",
      "17/17 [==============================] - 0s 12ms/step - loss: 0.0833 - accuracy: 0.9885 - val_loss: 2.1592 - val_accuracy: 0.4352\n",
      "Epoch 58/100\n",
      "17/17 [==============================] - 0s 12ms/step - loss: 0.0813 - accuracy: 0.9895 - val_loss: 2.1958 - val_accuracy: 0.4392\n",
      "Epoch 59/100\n",
      "17/17 [==============================] - 0s 12ms/step - loss: 0.0781 - accuracy: 0.9885 - val_loss: 2.1793 - val_accuracy: 0.4382\n",
      "Epoch 60/100\n",
      "17/17 [==============================] - 0s 13ms/step - loss: 0.0756 - accuracy: 0.9895 - val_loss: 2.2242 - val_accuracy: 0.4441\n",
      "Epoch 61/100\n",
      "17/17 [==============================] - 0s 13ms/step - loss: 0.0738 - accuracy: 0.9914 - val_loss: 2.2389 - val_accuracy: 0.4352\n",
      "Epoch 62/100\n",
      "17/17 [==============================] - 0s 14ms/step - loss: 0.0713 - accuracy: 0.9904 - val_loss: 2.2701 - val_accuracy: 0.4402\n",
      "Epoch 63/100\n",
      "17/17 [==============================] - 0s 14ms/step - loss: 0.0695 - accuracy: 0.9923 - val_loss: 2.2578 - val_accuracy: 0.4402\n",
      "Epoch 64/100\n",
      "17/17 [==============================] - 0s 13ms/step - loss: 0.0724 - accuracy: 0.9895 - val_loss: 2.2615 - val_accuracy: 0.4392\n",
      "Epoch 65/100\n",
      "17/17 [==============================] - 0s 14ms/step - loss: 0.0698 - accuracy: 0.9914 - val_loss: 2.2690 - val_accuracy: 0.4382\n",
      "Epoch 66/100\n",
      "17/17 [==============================] - 0s 15ms/step - loss: 0.0675 - accuracy: 0.9914 - val_loss: 2.2957 - val_accuracy: 0.4322\n",
      "Epoch 67/100\n",
      "17/17 [==============================] - 0s 16ms/step - loss: 0.0635 - accuracy: 0.9914 - val_loss: 2.3219 - val_accuracy: 0.4322\n",
      "Epoch 68/100\n",
      "17/17 [==============================] - 0s 16ms/step - loss: 0.0638 - accuracy: 0.9895 - val_loss: 2.2848 - val_accuracy: 0.4402\n",
      "Epoch 69/100\n",
      "17/17 [==============================] - 0s 16ms/step - loss: 0.0619 - accuracy: 0.9904 - val_loss: 2.3697 - val_accuracy: 0.4431\n",
      "Epoch 70/100\n",
      "17/17 [==============================] - 0s 17ms/step - loss: 0.0586 - accuracy: 0.9904 - val_loss: 2.3281 - val_accuracy: 0.4441\n",
      "Epoch 71/100\n",
      "17/17 [==============================] - 0s 16ms/step - loss: 0.0564 - accuracy: 0.9904 - val_loss: 2.3546 - val_accuracy: 0.4441\n",
      "Epoch 72/100\n",
      "17/17 [==============================] - 0s 16ms/step - loss: 0.0548 - accuracy: 0.9885 - val_loss: 2.3793 - val_accuracy: 0.4441\n",
      "Epoch 73/100\n",
      "17/17 [==============================] - 0s 16ms/step - loss: 0.0539 - accuracy: 0.9914 - val_loss: 2.3862 - val_accuracy: 0.4441\n",
      "Epoch 74/100\n",
      "17/17 [==============================] - 0s 16ms/step - loss: 0.0550 - accuracy: 0.9904 - val_loss: 2.3805 - val_accuracy: 0.4461\n",
      "Epoch 75/100\n",
      "17/17 [==============================] - 0s 16ms/step - loss: 0.0527 - accuracy: 0.9895 - val_loss: 2.4080 - val_accuracy: 0.4451\n",
      "Epoch 76/100\n",
      "17/17 [==============================] - 0s 16ms/step - loss: 0.0509 - accuracy: 0.9885 - val_loss: 2.4265 - val_accuracy: 0.4491\n",
      "Epoch 77/100\n",
      "17/17 [==============================] - 0s 16ms/step - loss: 0.0494 - accuracy: 0.9895 - val_loss: 2.4541 - val_accuracy: 0.4421\n",
      "Epoch 78/100\n",
      "17/17 [==============================] - 0s 16ms/step - loss: 0.0490 - accuracy: 0.9904 - val_loss: 2.4746 - val_accuracy: 0.4500\n",
      "Epoch 79/100\n",
      "17/17 [==============================] - 0s 17ms/step - loss: 0.0466 - accuracy: 0.9923 - val_loss: 2.4587 - val_accuracy: 0.4431\n",
      "Epoch 80/100\n",
      "17/17 [==============================] - 0s 17ms/step - loss: 0.0487 - accuracy: 0.9904 - val_loss: 2.5415 - val_accuracy: 0.4471\n",
      "Epoch 81/100\n",
      "17/17 [==============================] - 0s 16ms/step - loss: 0.0468 - accuracy: 0.9895 - val_loss: 2.4856 - val_accuracy: 0.4471\n",
      "Epoch 82/100\n",
      "17/17 [==============================] - 0s 16ms/step - loss: 0.0466 - accuracy: 0.9914 - val_loss: 2.5145 - val_accuracy: 0.4451\n",
      "Epoch 83/100\n",
      "17/17 [==============================] - 0s 16ms/step - loss: 0.0444 - accuracy: 0.9914 - val_loss: 2.4978 - val_accuracy: 0.4500\n",
      "Epoch 84/100\n",
      "17/17 [==============================] - 0s 16ms/step - loss: 0.0433 - accuracy: 0.9914 - val_loss: 2.5004 - val_accuracy: 0.4500\n",
      "Epoch 85/100\n",
      "17/17 [==============================] - 0s 16ms/step - loss: 0.0431 - accuracy: 0.9904 - val_loss: 2.5196 - val_accuracy: 0.4441\n",
      "Epoch 86/100\n",
      "17/17 [==============================] - 0s 16ms/step - loss: 0.0423 - accuracy: 0.9904 - val_loss: 2.5627 - val_accuracy: 0.4441\n",
      "Epoch 87/100\n",
      "17/17 [==============================] - 0s 16ms/step - loss: 0.0418 - accuracy: 0.9923 - val_loss: 2.5462 - val_accuracy: 0.4451\n",
      "Epoch 88/100\n",
      "17/17 [==============================] - 0s 16ms/step - loss: 0.0407 - accuracy: 0.9904 - val_loss: 2.5556 - val_accuracy: 0.4461\n",
      "Epoch 89/100\n",
      "17/17 [==============================] - 0s 16ms/step - loss: 0.0391 - accuracy: 0.9904 - val_loss: 2.5466 - val_accuracy: 0.4451\n",
      "Epoch 90/100\n",
      "17/17 [==============================] - 0s 16ms/step - loss: 0.0390 - accuracy: 0.9904 - val_loss: 2.5651 - val_accuracy: 0.4451\n",
      "Epoch 91/100\n",
      "17/17 [==============================] - 0s 16ms/step - loss: 0.0381 - accuracy: 0.9914 - val_loss: 2.5845 - val_accuracy: 0.4451\n",
      "Epoch 92/100\n",
      "17/17 [==============================] - 0s 16ms/step - loss: 0.0412 - accuracy: 0.9895 - val_loss: 2.5789 - val_accuracy: 0.4431\n",
      "Epoch 93/100\n",
      "17/17 [==============================] - 0s 16ms/step - loss: 0.0379 - accuracy: 0.9904 - val_loss: 2.5716 - val_accuracy: 0.4461\n",
      "Epoch 94/100\n",
      "17/17 [==============================] - 0s 16ms/step - loss: 0.0371 - accuracy: 0.9914 - val_loss: 2.6271 - val_accuracy: 0.4461\n",
      "Epoch 95/100\n",
      "17/17 [==============================] - 0s 17ms/step - loss: 0.0360 - accuracy: 0.9904 - val_loss: 2.6032 - val_accuracy: 0.4461\n",
      "Epoch 96/100\n",
      "17/17 [==============================] - 0s 17ms/step - loss: 0.0360 - accuracy: 0.9895 - val_loss: 2.6207 - val_accuracy: 0.4491\n",
      "Epoch 97/100\n",
      "17/17 [==============================] - 0s 17ms/step - loss: 0.0367 - accuracy: 0.9914 - val_loss: 2.6067 - val_accuracy: 0.4431\n",
      "Epoch 98/100\n",
      "17/17 [==============================] - 0s 16ms/step - loss: 0.0360 - accuracy: 0.9904 - val_loss: 2.6220 - val_accuracy: 0.4560\n",
      "Epoch 99/100\n",
      "17/17 [==============================] - 0s 16ms/step - loss: 0.0406 - accuracy: 0.9895 - val_loss: 2.6711 - val_accuracy: 0.4471\n",
      "Epoch 100/100\n",
      "17/17 [==============================] - 0s 16ms/step - loss: 0.0761 - accuracy: 0.9818 - val_loss: 2.6884 - val_accuracy: 0.4510\n",
      "INFO:tensorflow:Assets written to: modelNEW.tf\\assets\n"
     ]
    }
   ],
   "source": [
    "# Initialize the model - SRNN\n",
    "model = tf.keras.Sequential([\n",
    "    vectorize_layer,\n",
    "    #turns positive integers into dense vectors\n",
    "    tf.keras.layers.Embedding(\n",
    "        input_dim=max_words, output_dim=64, mask_zero=True),\n",
    "    #receives size of hidden state and passes to RNN\n",
    "    tf.keras.layers.SimpleRNN(64),\n",
    "    #multilayer perceptron for intial input then into 4 classifications\n",
    "    tf.keras.layers.Dense(64, activation='relu'),\n",
    "    tf.keras.layers.Dense(4, activation='softmax') #softmax instead of sigmoid for multiple classifications but one label\n",
    "])\n",
    "\n",
    "# Training the model\n",
    "model.compile(loss=tf.keras.losses.SparseCategoricalCrossentropy(),\n",
    "              optimizer=tf.keras.optimizers.Adam(1e-4), metrics=['accuracy'])\n",
    "\n",
    "model.fit(x=x_train, y=y_train, epochs=100,\n",
    "          batch_size=64, validation_data=(x_test, y_test))\n",
    "\n",
    "# Saving the model\n",
    "MODEL_NAME = \"modelNEW.tf\"\n",
    "save_model(model, MODEL_NAME)"
   ]
  }
 ],
 "metadata": {
  "interpreter": {
   "hash": "acfd08a7faa67adda30a139a14258a4609e125be16bd9d56539cb9e1d9f3c0a6"
  },
  "kernelspec": {
   "display_name": "Python 3.10.4 64-bit",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.6"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
